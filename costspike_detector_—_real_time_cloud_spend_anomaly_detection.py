# -*- coding: utf-8 -*-
"""CostSpike-Detector — Real-Time Cloud Spend Anomaly Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

# ============================================================
# CostSpike-Detector — Real-Time Cloud Spend Anomaly Detection (Colab Ready)
# ============================================================

import os
import json
import random
import time
from datetime import datetime, timezone, timedelta
import statistics

# Configuration
SPEND_FILE = "data/spend_history.json"
ANALYSIS_REPORT = "data/spend_anomaly_report.json"

HISTORY_DAYS = 30
INTERVAL_SECONDS = 1  # simulate one day per second for demo
ANOMALY_THRESHOLD_PERCENT = 50  # % above average to consider anomaly

# Ensure directories
os.makedirs(os.path.dirname(SPEND_FILE), exist_ok=True)
os.makedirs(os.path.dirname(ANALYSIS_REPORT), exist_ok=True)

# Generate dummy spend history if not exists
if not os.path.exists(SPEND_FILE):
    spend_history = []
    now = datetime.now(timezone.utc)
    for i in range(HISTORY_DAYS):
        day = (now - timedelta(days=HISTORY_DAYS - 1 - i)).strftime("%Y-%m-%d")
        spend = round(random.uniform(1000, 1500), 2)
        spend_history.append({"date": day, "cost_usd": spend})
    with open(SPEND_FILE, "w", encoding="utf-8") as f:
        json.dump(spend_history, f, indent=2)

def load_history(path):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def detect_anomaly(history, new_point, threshold_percent):
    costs = [d["cost_usd"] for d in history]
    avg = statistics.mean(costs)
    if new_point["cost_usd"] > avg * (1 + threshold_percent/100):
        return True, avg
    return False, avg

def run_detector(path, report_path, threshold_percent, interval_seconds):
    history = load_history(path)
    report = {
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "checked_points": 0,
        "anomalies": []
    }
    for _ in range(5):  # simulate 5 new daily points
        time.sleep(interval_seconds)
        new_date = (datetime.now(timezone.utc)).strftime("%Y-%m-%d")
        new_cost = round(random.uniform(1000, 2500), 2)
        new_point = {"date": new_date, "cost_usd": new_cost}
        history.append(new_point)
        anomaly, avg = detect_anomaly(history[:-1], new_point, threshold_percent)
        print(f"[{new_date}] Cost: ${new_cost} | Avg: ${round(avg,2)} | Anomaly: {anomaly}")
        if anomaly:
            report["anomalies"].append({"date": new_date, "cost_usd": new_cost, "avg_usd": round(avg,2)})
        report["checked_points"] += 1
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2)
    return report

if __name__ == "__main__":
    result = run_detector(SPEND_FILE, ANALYSIS_REPORT, ANOMALY_THRESHOLD_PERCENT, INTERVAL_SECONDS)
    print("✅ Spend anomaly detection complete:", result)